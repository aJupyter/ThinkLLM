{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2903, 0.7097, 0.0000],\n",
      "          [0.5406, 0.4594, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000]],\n",
      "\n",
      "         [[0.6244, 0.3756, 0.0000],\n",
      "          [0.6345, 0.3655, 0.0000],\n",
      "          [0.5756, 0.4244, 0.0000]],\n",
      "\n",
      "         [[0.3331, 0.6669, 0.0000],\n",
      "          [0.2868, 0.7132, 0.0000],\n",
      "          [0.5444, 0.4556, 0.0000]],\n",
      "\n",
      "         [[0.3406, 0.6594, 0.0000],\n",
      "          [0.3485, 0.6515, 0.0000],\n",
      "          [0.5029, 0.4971, 0.0000]],\n",
      "\n",
      "         [[0.6410, 0.3590, 0.0000],\n",
      "          [0.5268, 0.4732, 0.0000],\n",
      "          [0.5097, 0.4903, 0.0000]],\n",
      "\n",
      "         [[0.3452, 0.6548, 0.0000],\n",
      "          [0.5306, 0.4694, 0.0000],\n",
      "          [0.6131, 0.3869, 0.0000]],\n",
      "\n",
      "         [[0.4533, 0.5467, 0.0000],\n",
      "          [0.4557, 0.5443, 0.0000],\n",
      "          [0.3538, 0.6462, 0.0000]],\n",
      "\n",
      "         [[0.8310, 0.1690, 0.0000],\n",
      "          [0.6612, 0.3388, 0.0000],\n",
      "          [0.5105, 0.4895, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2249, 0.7751, 0.0000],\n",
      "          [0.6074, 0.3926, 0.0000],\n",
      "          [0.4348, 0.5652, 0.0000]],\n",
      "\n",
      "         [[0.4929, 0.5071, 0.0000],\n",
      "          [0.4272, 0.5728, 0.0000],\n",
      "          [0.5133, 0.4867, 0.0000]],\n",
      "\n",
      "         [[0.4539, 0.5461, 0.0000],\n",
      "          [0.2150, 0.7850, 0.0000],\n",
      "          [0.4968, 0.5032, 0.0000]],\n",
      "\n",
      "         [[0.7558, 0.2442, 0.0000],\n",
      "          [0.5556, 0.4444, 0.0000],\n",
      "          [0.4917, 0.5083, 0.0000]],\n",
      "\n",
      "         [[0.5880, 0.4120, 0.0000],\n",
      "          [0.5558, 0.4442, 0.0000],\n",
      "          [0.6178, 0.3822, 0.0000]],\n",
      "\n",
      "         [[0.6687, 0.3313, 0.0000],\n",
      "          [0.3575, 0.6425, 0.0000],\n",
      "          [0.6666, 0.3334, 0.0000]],\n",
      "\n",
      "         [[0.4274, 0.5726, 0.0000],\n",
      "          [0.3969, 0.6031, 0.0000],\n",
      "          [0.3800, 0.6200, 0.0000]],\n",
      "\n",
      "         [[0.6102, 0.3898, 0.0000],\n",
      "          [0.7577, 0.2423, 0.0000],\n",
      "          [0.7034, 0.2966, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_nums:int, dim:int, drop_radio:float=0.1):\n",
    "        super().__init__()\n",
    "        self.head_nums = head_nums\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // head_nums\n",
    "\n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "\n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.att_drop = nn.Dropout(drop_radio)\n",
    "\n",
    "    def forward(self, x, attention_mask:torch.Tensor=None):\n",
    "        # x shape (batch_size, seq_len, dim)\n",
    "        bs, seq_len, dim = x.shape\n",
    "        # QKV shape (batch_size, seq_len, dim)\n",
    "        Q = self.q_proj(x)\n",
    "        K = self.k_proj(x)\n",
    "        V = self.v_proj(x)\n",
    "\n",
    "        # (batch_size, head_nums, seq_len, head_dim)\n",
    "        q_state = Q.reshape(bs, seq_len, self.head_nums, self.head_dim).transpose(1, 2)\n",
    "        k_state = K.reshape(bs, seq_len, self.head_nums, self.head_dim).transpose(1, 2)\n",
    "        v_state = V.reshape(bs, seq_len, self.head_nums, self.head_dim).transpose(1, 2)\n",
    "\n",
    "\n",
    "        att_val = q_state @ k_state.transpose(-1, -2) / math.sqrt(self.head_dim)\n",
    "\n",
    "        # attention_mask (batch, head_nums, seq, seq)\n",
    "        if attention_mask is not None:\n",
    "            att_val = att_val.masked_fill(\n",
    "                attention_mask == 0,\n",
    "                float('-inf')\n",
    "            )\n",
    "        \n",
    "        # (batch_size, head_nums, seq, seq)\n",
    "        att_weight = torch.softmax(att_val, dim=-1)\n",
    "        print(att_weight)\n",
    "\n",
    "        # dropout\n",
    "        att_weight = self.att_drop(att_weight)\n",
    "\n",
    "        # output_state (batch_size, nums_head, seq_len, head_dim)\n",
    "        output_state = att_weight @ v_state\n",
    "\n",
    "        # output (batch_size, seq_len, dim)\n",
    "        output = output_state.transpose(1, 2).reshape(bs, seq_len, dim)\n",
    "\n",
    "        output = self.out_proj(output)\n",
    "        return output     \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 3, 128)\n",
    "    model = MultiHeadAttention(8, 128)\n",
    "    attention_mask = torch.tensor(\n",
    "        [\n",
    "            [1, 0, 0],\n",
    "            [1, 1, 0],\n",
    "            [1, 1, 0]\n",
    "        ]\n",
    "    ).unsqueeze(1).unsqueeze(2).expand(3, 8, 3, 3)\n",
    "\n",
    "    # 用repeat的方式扩展attention_mask\n",
    "    attention_mask = torch.tensor(\n",
    "        [\n",
    "            [1, 0, 0],\n",
    "            [1, 1, 0],\n",
    "            [1, 1, 0]\n",
    "        ]\n",
    "    ).unsqueeze(1).unsqueeze(2).repeat(1, 8, 3, 1)\n",
    "    \n",
    "    print(model(x, attention_mask).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4864, 0.5136],\n",
      "          [0.4827, 0.5173]],\n",
      "\n",
      "         [[0.4970, 0.5030],\n",
      "          [0.5078, 0.4922]],\n",
      "\n",
      "         [[0.5348, 0.4652],\n",
      "          [0.5167, 0.4833]],\n",
      "\n",
      "         [[0.5250, 0.4750],\n",
      "          [0.5303, 0.4697]],\n",
      "\n",
      "         [[0.5142, 0.4858],\n",
      "          [0.4925, 0.5075]],\n",
      "\n",
      "         [[0.4912, 0.5088],\n",
      "          [0.4937, 0.5063]],\n",
      "\n",
      "         [[0.4628, 0.5372],\n",
      "          [0.4619, 0.5381]],\n",
      "\n",
      "         [[0.5207, 0.4793],\n",
      "          [0.5397, 0.4603]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [1.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 2, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# nums_key_value_head设置为1就是MQA，设置为head_nums就是MHA\n",
    "class GroupQueryAttention(nn.Module):\n",
    "    def __init__(self, dim:int, head_nums:int, nums_key_value_head:int, drop_radio:float=0.1):\n",
    "        # nums_key_valu_head 相当于是KV的head数\n",
    "        super().__init__()\n",
    "\n",
    "        assert dim % head_nums == 0 # 满足整除\n",
    "        assert head_nums % nums_key_value_head == 0 # N个query head为一组\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // head_nums\n",
    "        self.head_nums = head_nums\n",
    "        self.nums_key_value_head = nums_key_value_head\n",
    "        \n",
    "        self.q_proj = nn.Linear(dim, self.head_nums * self.head_dim)\n",
    "        self.k_proj = nn.Linear(dim, nums_key_value_head * self.head_dim)\n",
    "        self.v_proj = nn.Linear(dim, nums_key_value_head * self.head_dim)\n",
    "\n",
    "        self.att_weight_drop = nn.Dropout(drop_radio)\n",
    "        self.o_proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, attention_mask:torch.Tensor=None):\n",
    "        # x shape (batch_size, seq_len, dim)\n",
    "        batch_size, seq_len, dim = x.shape\n",
    "\n",
    "        # QKV\n",
    "        # Q (batch_size, seq_len, head_nums*head_dim)\n",
    "        Q = self.q_proj(x)\n",
    "        # KV (batch_size, seq_len, nums_key_value_head*head_dim)\n",
    "        K = self.k_proj(x)\n",
    "        V = self.v_proj(x)\n",
    "\n",
    "        # q_state (batch_size, head_nums, seq_len, head_dim)\n",
    "        q_state = Q.reshape(batch_size, seq_len, self.head_nums, self.head_dim).transpose(1, 2)\n",
    "        # k_state, v_state (batch_size, nums_key_value_head, seq_len, head_dim)\n",
    "        k_state = K.reshape(batch_size, seq_len, self.nums_key_value_head, self.head_dim).transpose(1, 2)\n",
    "        v_state = V.reshape(batch_size, seq_len, self.nums_key_value_head, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # k,v repeat 广播操作 (batch_size, head_nums, seq_len, head_dim)\n",
    "        k_state = k_state.repeat_interleave(\n",
    "            self.head_nums // self.nums_key_value_head, dim=1)\n",
    "        v_state = v_state.repeat_interleave(\n",
    "            self.head_nums // self.nums_key_value_head, dim=1)\n",
    "\n",
    "        # attention_val (batch_size, head_nums, seq_len, seq_len)\n",
    "        attention_val = q_state @ k_state.transpose(-1, -2) / math.sqrt(self.head_dim)\n",
    "\n",
    "        # attention_mask\n",
    "        if attention_mask is not None:\n",
    "            attention_val = attention_val.masked_fill(\n",
    "                attention_mask == 0,\n",
    "                float('-inf')\n",
    "            )\n",
    "        attention_weight = torch.softmax(attention_val, dim=-1) \n",
    "        print(attention_weight)\n",
    "\n",
    "        # dropout\n",
    "        attention_weight = self.att_weight_drop(attention_weight)\n",
    "\n",
    "        # output_state (batch_size, head_nums, seq_len, head_dim)\n",
    "        output_state = attention_weight @ v_state\n",
    "        \n",
    "        # (batch_size, seq_len, dim)\n",
    "        output = output_state.transpose(1, 2).reshape(batch_size, seq_len, -1)\n",
    "\n",
    "        output = self.o_proj(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    x = torch.rand(3, 2, 128)\n",
    "\n",
    "    # (batch_size, head_nums, seq_len, seq_len) -> 3, 8, 2, 2\n",
    "    attention_mask = torch.tensor(\n",
    "        [\n",
    "            [1, 1],\n",
    "            [1, 0],\n",
    "            [1, 0]\n",
    "        ]\n",
    "    ).unsqueeze(1).unsqueeze(2).repeat(1, 8, 2, 1)\n",
    "\n",
    "    attention_mask = torch.tensor(\n",
    "        [\n",
    "            [1, 1],\n",
    "            [1, 0],\n",
    "            [1, 0]\n",
    "        ]\n",
    "    ).unsqueeze(1).unsqueeze(2).expand(3, 8, 2, 2)\n",
    "    model = GroupQueryAttention(dim=128,head_nums=8, nums_key_value_head=2)\n",
    "    print(model(x, attention_mask=attention_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wxz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
